# Projeto Breweries

O projeto Breweries visa buscar informa√ß√µes abertas sobre cervejaria ao redor do mundo.

O projeto foi desenvolvido de forma a executar localmente, de forma a facilitar a configura√ß√£o e simplificar o a execu√ß√£o do projeto.

# Tecnologias utilizadas

- [Apache Spark](https://spark.apache.org/)
  - [PySpark](https://spark.apache.org/docs/latest/api/python/index.html)

- [Apache Airflow](https://airflow.apache.org/)
  - [Postgres](https://www.postgresql.org/) como armazenamento do Apache Airflow

- [Dremio](https://www.dremio.com/) √© uma plataforma de Lakehouse e foi principalmente utilizado para cat√°logo

- [Docker](https://www.docker.com/)
  - [Docker-Compose](https://docs.docker.com/compose/)

# Hierarquia das pastas

Pastas versionadas:

- üìÅ dags
  - Orquestra√ß√£o de Jobs utilizanod Apache Airflow
- üìÅ src
  - Jobs em Apache Spark
- üìÅ tests
  - Testes unit√°rios

Pastas geradas:

- üìÅ data
  - Volume montado com o Data Lake gerado
- üìÅ logs
  - Volume montado com o logs de execu√ß√£o do Apache Airflow

# Arquitetura

![Diagrama de arquitetura](./diagrama-arquitetura.png)

# Monitoramento e Alertas

A estrat√©gia de monitoramento deve ser feito em camadas:

- Periodicamente devemos verificar a interface do Apache Airflow para verificar:
  - Erros catastr√≥ficos nos Jobs executados
  - Tempo de processamento em cada execu√ß√£o
  - Logs de execu√ß√£o de cada execu√ß√£o.

Em casos de **erros catastr√≥ficos** ser√£o enviados para um email com acesso aos respons√°veis de plant√£o.

# M√©tricas de qualidade

Em rela√ß√£o as m√©tricas de qualiade podemos mensurar:

- Volume de dados processados a cada execu√ß√£o vs hist√≥rico
- Contagem de valores nulos em colunas cr√≠ticas
- Regras de neg√≥cio espec√≠ficas

# Orquestra√ß√£o

## breweries_bronze

**Objetivo:** download das informa√ß√µes da base aberta de cervejaria.

**Frequ√™ncia:** podemos verificar a frequ√™ncia de atualiza√ß√£o da base de dados aberta e nos adaptarmos a essa frequ√™ncia.

**Fonte de dados:**

- [Open Brewery DB](https://www.openbrewerydb.org/)
  - [List Breweries](https://www.openbrewerydb.org/documentation#list-breweries)
  - [Metadata](https://www.openbrewerydb.org/documentation#metadata)

**Destino dos dados:**

- Spark warehouse no container `spark-master`
  - Caminho: `spark-warehouse/breweries_bronze`
  - √â montado um volume entre o container e o host `./data:/opt/bitnami/spark/spark-warehouse`

**Apache Airflow:**

- DAG: `Breweries`
- Operadores: `SparkSubmitOperator`
- Script: `src/breweries_bronze.py`
- Depend√™ncia: nenhum
- Pol√≠tica de retentativa: m√°ximo de 3
- Execu√ß√µes concorrentes: 1 execu√ß√£o concorrente

### L√≥gica de processamento

O `List Breweries` √© endpoint que retorna todas as cervejarias paginadas, exemplo:

```py
# GET https://api.openbrewerydb.org/v1/breweries?page=15&per_page=3
```

Assim, foi desenvolvido um UDF (User Defined Function) para fazer essas requisi√ß√µes e poder utilizar todos os recursos do cluster.

Para isso partimos do endpoint `Metadata` que prov√™ a quantidade de cervejaria e dividimos isso me p√°ginas.

### Tratamento de erros

O Job `breweries_bronze` pode apresentar as seguintes exce√ß√µes:

- Falha ao buscar os metadados
- Falha ao analisar os metadados
- Falha ao buscar os dados de cervejarias

Para qualquer um dos casos acima o Job ir√° ser encerrado e marcado como falha.

## breweries_silver

**Objetivo:** refinamento dos dados de cervejaria e particionamento para preparar os dados para futuros processamentos anal√≠ticos.

**Frequ√™ncia:** podemos verificar a frequ√™ncia de atualiza√ß√£o da base de dados aberta e nos adaptarmos a essa frequ√™ncia.

**Fonte de dados:**

- Resultado do Job `breweries_bronze`

**Destino dos dados:**

- Spark warehouse no container `spark-master`
  - Caminho: `spark-warehouse/breweries`
  - √â montado um volume entre o container e o host `./data:/opt/bitnami/spark/spark-warehouse`

**Apache Airflow:**

- DAG: `Breweries`
- Operadores: `SparkSubmitOperator`
- Script: `src/breweries_silver.py`
- Depend√™ncia: Dados atualizados `breweries_bronze`
- Pol√≠tica de retentativa: m√°ximo de 3
- Execu√ß√µes concorrentes: 1 execu√ß√£o concorrente

### L√≥gica de processamento

Particionamento por localiza√ß√£o. Localiza√ß√£o √© composta pelo campo `country` da cervejaria.

√â necess√°rio fazer uma transforma√ß√£o no campo `country` para remover espa√ßos brancos desnecess√°rios no come√ßo e no final do nome.

## breweries_by_type_and_location

**Objetivo:** agrega√ß√£o das cervejarias por tipo de localiza√ß√£o para buscar informa√ß√µes como o total de cervejarias.

**Frequ√™ncia:** podemos verificar a frequ√™ncia de atualiza√ß√£o da base de dados aberta e nos adaptarmos a essa frequ√™ncia.

**Fonte de dados:**

- Resultado do Job `breweries_silver`

**Destino dos dados:**

- Spark warehouse no container `spark-master`
  - Caminho: `spark-warehouse/breweries_by_type_and_location_VW`
  - √â montado um volume entre o container e o host `./data:/opt/bitnami/spark/spark-warehouse`

**Apache Airflow:**

- DAG: `Breweries`
- Operadores: `SparkSubmitOperator`
- Script: `src/breweries_silver.py`
- Depend√™ncia: Dados atualizados `breweries`
- Pol√≠tica de retentativa: m√°ximo de 3
- Execu√ß√µes concorrentes: 1 execu√ß√£o concorrente

### L√≥gica de processamento

Nenhum processamento complexo foi empregado.